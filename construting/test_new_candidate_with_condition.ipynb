{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from os.path import join as pjoin\n",
    "from glob import iglob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import distributed\n",
    "from models import data_loader, model_builder\n",
    "from models.data_loader import load_dataset\n",
    "from models.model_builder import ExtSummarizer\n",
    "from models.trainer_ext import build_trainer\n",
    "from others.logging import logger, init_logger\n",
    "\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers', 'encoder', 'ff_actv', 'use_interval', 'rnn_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/data/ksb/'\n",
    "bert_root_path = pjoin(root_path, 'BertSum/PreSumm')\n",
    "bert_model_dir = pjoin(bert_root_path, 'models')\n",
    "\n",
    "data_dir = pjoin(root_path, 'cnn-dailymail/finished_files')\n",
    "\n",
    "three_data_dir = pjoin(root_path, 'three-mat')\n",
    "three_data_test = pjoin(three_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function 비교  \n",
    "\n",
    "*Trained Model parameter 필요*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_similarity(inputs, summaries):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    cos_similarity_list = []\n",
    "    for input_, summary_ in zip(inputs, summaries):\n",
    "        try:\n",
    "            tfidf_matrix = tfidf_vectorizer.fit_transform([input_, summary_])\n",
    "\n",
    "            similarity = cosine_similarity(tfidf_matrix[0] , tfidf_matrix[1])[0][0]\n",
    "        except ValueError:\n",
    "            similarity = 0.0\n",
    "            \n",
    "        cos_similarity_list.append(similarity)\n",
    "\n",
    "    return cos_similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "\n",
    "data_list = []\n",
    "for data_p in iglob(pjoin(three_data_test, '**.json'), recursive=False):\n",
    "    \n",
    "    with open(data_p,'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origin candidate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sim_list = []\n",
    "ref_sim_list = []\n",
    "\n",
    "min_doc_sim_list = []\n",
    "max_doc_sim_list = []\n",
    "\n",
    "doc_rouge_list = []\n",
    "ref_rouge_list = []\n",
    "\n",
    "max_ref_rouge_list = []\n",
    "min_ref_rouge_list = []\n",
    "\n",
    "for data in data_list:\n",
    "    candidates = data['candidates']\n",
    "    article = data['article']\n",
    "    abstract = data[\"abstract\"]\n",
    "    \n",
    "    sim_list = [np.mean(get_cos_similarity(article, cand[0])) for cand in candidates]\n",
    "    doc_sim_list += sim_list\n",
    "    min_doc_sim_list += [min(sim_list)]\n",
    "    max_doc_sim_list += [max(sim_list)]\n",
    "    \n",
    "    ref_sim_list += [np.mean(get_cos_similarity(abstract, cand[0])) for cand in candidates]\n",
    "    \n",
    "    doc_rouge_list +=[rouge.get_scores('\\n'.join(cand[0]), '\\n'.join(article))[0]['rouge-l']['f'] for cand in candidates]\n",
    "    \n",
    "    rouge_list = [rouge.get_scores('\\n'.join(cand[0]), '\\n'.join(abstract))[0]['rouge-l']['f'] for cand in candidates]\n",
    "    ref_rouge_list += rouge_list\n",
    "    min_ref_rouge_list += [min(rouge_list)]\n",
    "    max_ref_rouge_list += [max(rouge_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cosine similarity between document and summaries : 0.2746\n",
      "Mean cosine similarity between reference and summaries : 0.1834\n",
      "\n",
      "Min cosine similarity between document and summaries : 0.1434\n",
      "Max cosine similarity between document and summaries : 0.4457\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean cosine similarity between document and summaries : {}\".format(round(np.mean(doc_sim_list), 4)))\n",
    "print(\"Mean cosine similarity between reference and summaries : {}\\n\".format(round(np.mean(ref_sim_list), 4)))\n",
    "\n",
    "print(\"Min cosine similarity between document and summaries : {}\".format(round(np.mean(min_doc_sim_list), 4)))\n",
    "print(\"Max cosine similarity between document and summaries : {}\".format(round(np.mean(max_doc_sim_list), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rouge score between document and summaries : 0.3288\n",
      "Mean Rouge score between reference and summaries : 0.4156\n",
      "\n",
      "Min Rouge score between reference and summaries : 0.358\n",
      "Max Rouge score between reference and summaries : 0.4719\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Rouge score between document and summaries : {}\".format(round(np.mean(doc_rouge_list), 4)))\n",
    "print(\"Mean Rouge score between reference and summaries : {}\\n\".format(round(np.mean(ref_rouge_list), 4)))\n",
    "\n",
    "print(\"Min Rouge score between reference and summaries : {}\".format(round(np.mean(min_ref_rouge_list), 4)))\n",
    "print(\"Max Rouge score between reference and summaries : {}\".format(round(np.mean(max_ref_rouge_list), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tok = BertTokenizer.from_pretrained('bert-base-uncased', verbose=False)\n",
    "\n",
    "def bert_encode(x, max_len=-1):\n",
    "    cls_token_id = tok.cls_token_id\n",
    "    sep_token_id = tok.sep_token_id\n",
    "\n",
    "    _ids = tok.encode(x, add_special_tokens=False)\n",
    "    ids = [cls_token_id] # [CLS]\n",
    "    if max_len > 0:\n",
    "        ids.extend(_ids[:max_len - 2])\n",
    "    else:\n",
    "        ids.extend(_ids[:512 - 2])\n",
    "    ids.append(sep_token_id) # [SEP], meaning end of sentence\n",
    "    return ids\n",
    "\n",
    "def bert_decode(x):\n",
    "    result = tok.decode(x, skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_trigram(src, tgt):\n",
    "    if len(tgt) < 3 or len(src) < 3:\n",
    "        return False\n",
    "    \n",
    "    tgt_trigrams = [(tgt[i-1],tgt[i],tgt[i+1]) for i in range(1,len(tgt)-1)]\n",
    "    src_trigrams = [(src[i-1],src[i],src[i+1]) for i in range(1,len(src)-1)]\n",
    "    \n",
    "    for src_tri in src_trigrams:\n",
    "        if src_tri in tgt_trigrams:\n",
    "            return True ## Detect trigram overlapped with target\n",
    "        \n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_4_gram(src, tgt):\n",
    "    if len(tgt) < 4 or len(src) < 4:\n",
    "        return False\n",
    "    \n",
    "    tgt_4_grams = [(tgt[i-2], tgt[i-1],tgt[i],tgt[i+1]) for i in range(2,len(tgt)-1)]\n",
    "    src_4_grams = [(src[i-2], src[i-1],src[i],src[i+1]) for i in range(2,len(src)-1)]\n",
    "    \n",
    "    for src_gram in src_4_grams:\n",
    "        if src_gram in tgt_4_grams:\n",
    "            return True ## Detect 4-gram overlapped with target\n",
    "        \n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_5_gram(src, tgt):\n",
    "    if len(tgt) < 5 or len(src) < 5:\n",
    "        return False\n",
    "    \n",
    "    tgt_5_grams = [(tgt[i-2], tgt[i-1],tgt[i],tgt[i+1], tgt[i+2]) for i in range(2,len(tgt)-2)]\n",
    "    src_5_grams = [(src[i-2], src[i-1],src[i],src[i+1], src[i+2]) for i in range(2,len(src)-2)]\n",
    "    \n",
    "    for src_gram in src_5_grams:\n",
    "        if src_gram in tgt_5_grams:\n",
    "            return True ## Detect 5-gram overlapped with target\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ngram_list(src, tgt_list, n_gram='trigram'):\n",
    "    \n",
    "    if n_gram =='trigram':\n",
    "        return sum([detect_trigram(src, tgt) for tgt in tgt_list]) > 0\n",
    "    elif n_gram =='4-gram':\n",
    "        return sum([detect_4_gram(src, tgt) for tgt in tgt_list]) > 0\n",
    "    else :\n",
    "        return sum([detect_4_gram(src, tgt) for tgt in tgt_list])>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_set(sent_set, reference=None, n_gram='trigram'):\n",
    "    \n",
    "    assert n_gram in ['trigram', '4-gram','5-gram']\n",
    "        \n",
    "    if n_gram == 'trigram':\n",
    "        detect_ngram = detect_trigram\n",
    "    elif n_gram == '4-gram':\n",
    "        detect_ngram = detect_4_gram\n",
    "    else:\n",
    "        detect_ngram = detect_5_gram\n",
    "        \n",
    "    \n",
    "    possible_set_ids = []\n",
    "    \n",
    "    for sent_id, sent, txt_sent in sent_set:\n",
    "        possible_2_sent_idx = []\n",
    "        \n",
    "        # number of summary sentences = 2\n",
    "        for tgt_sent_id, tgt_sent, tgt_sent_txt in sent_set[sent_id+1:]:\n",
    "            \n",
    "            # Detect n-gram (default= trigram) \n",
    "            if not detect_ngram(src=sent, tgt=tgt_sent):\n",
    "                possible_2_sent_idx.append(set([sent_id, tgt_sent_id]))\n",
    "                \n",
    "        possible_3_sent_idx = copy.deepcopy(possible_2_sent_idx)\n",
    "        \n",
    "        # number of summary sentences = 3\n",
    "        for tgt_sent_id, tgt_sent, tgt_sent_txt in sent_set[sent_id+1:]:\n",
    "            for poss_sent_ids in possible_2_sent_idx:\n",
    "                \n",
    "                poss_sent = [sent_set[ids][1] for ids in poss_sent_ids]\n",
    "                if not detect_ngram_list(src=tgt_sent, tgt_list=poss_sent, n_gram=n_gram):\n",
    "                    poss_3_ids = copy.deepcopy(poss_sent_ids)\n",
    "                    poss_3_ids.add(tgt_sent_id)\n",
    "                    \n",
    "                    possible_3_sent_idx.append(poss_3_ids)\n",
    "                    \n",
    "        possible_sent_idx = possible_2_sent_idx + possible_3_sent_idx\n",
    "        \n",
    "        for ids in possible_sent_idx:\n",
    "            if not ids in possible_set_ids:\n",
    "                possible_set_ids.append(ids)\n",
    "\n",
    "    return possible_set_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylcs\n",
    "\n",
    "def compute_txt_redundancy_score(candidate_id):\n",
    "\n",
    "    cand_num = len(candidate_id)\n",
    "    \n",
    "    score = torch.zeros([cand_num], dtype=torch.float64)\n",
    "        \n",
    "    def _compute_redundancy(cand):\n",
    "        redundancy = 0.0\n",
    "        \n",
    "        for i, src_sen in enumerate(cand):\n",
    "            for j, tgt_sen in enumerate(cand[i+1:]):\n",
    "                if i != j:\n",
    "                    lcs_val = pylcs.lcs(src_sen, tgt_sen)\n",
    "                    redundancy += lcs_val \n",
    "        \n",
    "        sents_len = sum([len(s) for sents in cand for s in sents])\n",
    "        return redundancy / sents_len\n",
    "\n",
    "    for i in range(cand_num):\n",
    "        score[i] = np.mean(_compute_redundancy(candidate_id[i]))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(src, tgt, rouge_score='rouge-1', metric='f'):\n",
    "    sc = rouge.get_scores(' '.join(src), ' '.join(tgt))[0]\n",
    "    return sc[rouge_score][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_path = pjoin(three_data_dir,'reconstructed_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origin Candidate\n",
    "origin_ref_rouges = []\n",
    "origin_redun_scores = []\n",
    "\n",
    "origin_doc_sims = []\n",
    "origin_ref_sims = []\n",
    "\n",
    "\n",
    "# Reconstructed Candidate\n",
    "refine_ref_rouges = []\n",
    "refine_redun_scores = []\n",
    "\n",
    "refine_doc_sims = []\n",
    "refine_ref_sims = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin ROUGE : [0.4474, 0.5116, 0.4776]\n",
      "New Candidate ROUGE : [0.6027, 0.6027, 0.6027]\n",
      "\n",
      "['he was not booked by the referee but could face a heavy retrospective ban .', 'arango had earlier curled in a magnificent free kick for his team to bring them level after falling 2-0 down .', \"juan arango bites jesus zavela in club tijuana 's 4-3 defeat by monterrey in the mexican league .\"]\n",
      "[[\"juan arango bites jesus zavela in a moment of madness in club tijuana 's 4-3 defeat by monterrey in the mexican league .\", 'the venezuelan icon sank his teeth into the shoulder of the opponent as his temper flared in the defeat .', 'he was not booked by the referee but could face a heavy retrospective ban .', 'arango had earlier curled in a magnificent free kick for his team to bring them level after falling 2-0 down .'], 0.40383502768823876] \n",
      "\n",
      "['juan arango escaped punishment from the referee for biting jesus zavela .', 'he could face a retrospective punishment for the incident .', \"arango had earlier scored a free kick in his team 's 4-3 defeat .\"]\n",
      "[[[\"club tijuana star juan arango conjured memories luis suarez in his team 's 4-3 defeat by monterrey in the mexican league - but it was not through prodigious scoring .\", 'he was not booked by the referee but could face a heavy retrospective ban .', 'juan arango ( left ) bites the shoulder of opponent jesus zavela in a moment of madness'], 0.40032206119162644], [[\"juan arango bites jesus zavela in a moment of madness in club tijuana 's 4-3 defeat by monterrey in the mexican league .\", 'the venezuelan icon sank his teeth into the shoulder of the opponent as his temper flared in the defeat .', 'he was not booked by the referee but could face a heavy retrospective ban .', 'arango had earlier curled in a magnificent free kick for his team to bring them level after falling 2-0 down .'], 0.40383502768823876], [[\"juan arango bites jesus zavela in club tijuana 's 4-3 defeat by monterrey in the mexican league .\", 'the venezuelan icon sank his teeth into the shoulder of jesus zavala in a moment of madness .', 'he was not booked by the referee but could face a heavy retrospective ban .'], 0.38732708612226685]] \n",
      "\n",
      "Origin ROUGE : [0.4138, 0.3614, 0.375]\n",
      "New Candidate ROUGE : [0.5, 0.48, 0.4878]\n",
      "\n",
      "['the 22-year-old has enjoyed a successful loan spell at nottingham forest .', 'gary gardner will report to aston villa for pre-season training to be assessed by tim sherwood .']\n",
      "[['gardner has enjoyed a successful loan spell at nottingham forest and scored a superb free-kick in front of the villa manager during the defeat to watford at the city ground .', 'gary gardner ( left ) will report to aston villa for pre-season training to be assessed by tim sherwood'], 0.34344436179298565] \n",
      "\n",
      "[\"gary gardner confirms he 'll report to aston villa for pre-season training .\", 'the 22-year-old is out on loan at championship side nottingham forest .', 'tim sherwood is keen to asses gardner ahead of next season .', \"the midfielder would prefer a move back to forest if villa does n't wok out .\", 'click here for all the latest aston villa news .']\n",
      "[[['gardner has enjoyed a successful loan spell at nottingham forest and scored a superb free-kick in front of the villa manager during the defeat to watford at the city ground .', 'gary gardner ( left ) will report to aston villa for pre-season training to be assessed by tim sherwood'], 0.34344436179298565], [['gary gardner has enjoyed a successful loan spell at nottingham forest .', 'the 22-year-old scored a superb free-kick in front of tim sherwood during the defeat to watford at the city ground .', 'sherwood is keen to see gardner train day-to-day before making up his mind .'], 0.3193101358238973], [['gary gardner will report to aston villa for pre-season training to be assessed by tim sherwood .', 'the villa boss has inspired the club since being appointed and helped lead them to an fa cup final .', 'gardner scored a stunning free-kick against watford with sherwood in attendance at the city ground .', 'the 22-year-old has enjoyed a successful loan spell at nottingham forest .'], 0.3475485564304462]] \n",
      "\n",
      "Origin ROUGE : [0.3774, 0.3579, 0.2936]\n",
      "New Candidate ROUGE : [0.4557, 0.4557, 0.4719]\n",
      "\n",
      "['the unusual format has been captured in a series of photographs by visual journalist anna erickson .', \"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\", 'bud dodson , 57 , is a maintenance man who watches over the parking lot .']\n",
      "[['the unusual format has been captured in a series of photographs by visual journalist anna erickson .', \"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\", 'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'], 0.32618005880037965] \n",
      "\n",
      "[\"around 30 people live a floating life in seattle 's sodo ( south of downtown ) area in their rvs .\", 'there is one parking lot in particular where the owner lets them act as watchmen in exchange for a spot to live .', 'visual journalist anna erickson , who photographed the community , said they are just grateful to have a home .']\n",
      "[[['the unusual format has been captured in a series of photographs by visual journalist anna erickson .', \"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\", 'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'], 0.32618005880037965], [[\"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\", 'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .', 'bud dodson , 57 , is a maintenance man who watches over the parking lot .'], 0.2774552491533624], [['the unusual format has been captured in a series of photographs by visual journalist anna erickson .', 'she came across them when she stopped to ask a seemingly homeless man for directions .', 'john worden , 52 , has been living in his $ 200 vehicle for years since his apartment burned down and he was left homeless .', 'bud dodson , 57 , watches over the parking lot in exchange for a semi-permanent spot .'], 0.2726937669376694]] \n",
      "\n",
      "Origin ROUGE : [0.4694, 0.5088, 0.4906]\n",
      "New Candidate ROUGE : [0.5455, 0.54, 0.5347]\n",
      "\n",
      "['messi had a light training session alongside compatriot javier mascherano as he recovers from foot injury', \"lionel messi has recovered from his foot injury and should be fit for sunday 's la liga match with celta vigo .\", \"the argentina forward sat out both of his country 's friendlies against el salvador and ecuador over the international break .\"]\n",
      "[[\"lionel messi has recovered from his foot injury and should be fit for sunday 's la liga match with celta vigo .\", \"the argentina forward sat out both of his country 's friendlies against el salvador and ecuador over the international break .\", \"the 27-year-old sustained the blow to his right foot in last month 's ` clasico ' win over real madrid .\", 'messi trained alongside compatriot javier mascherano on thursday and both are expected to rejoin the rest of the squad on friday .'], 0.363476733977173] \n",
      "\n",
      "['messi completed a light training session at barcelona on thursday .', 'he has almost recovered from a foot injury sustained in clasico with real .', 'argentina star sat out friendly matches with el salvador and ecuador .', 'barcelona hoping to maintain la liga lead against celta vigo .', \"luis enrique 's team remain on course for the treble .\"]\n",
      "[[[\"lionel messi has recovered from his injured foot and should be fit to start sunday 's la liga match with celta vigo .\", 'messi had a light training session alongside compatriot javier mascherano as he recovers from foot injury', 'the pair returned to the barcelona training ground on thursday , 24 hours ahead of schedule'], 0.34374721851357365], [[\"lionel messi has recovered from his foot injury and should be fit for sunday 's la liga match with celta vigo .\", \"the argentina forward sat out both of his country 's friendlies against el salvador and ecuador over the international break .\", \"the 27-year-old sustained the blow to his right foot in last month 's ` clasico ' win over real madrid .\", 'messi trained alongside compatriot javier mascherano on thursday and both are expected to rejoin the rest of the squad on friday .'], 0.363476733977173], [[\"lionel messi trained with compatriot javier mascherano on thursday ahead of sunday 's trip to celta vigo .\", 'the argentina forward has recovered from his foot injury and should be fit to start .', \"messi sat out both of his country 's friendlies against el salvador and ecuador over the international break .\", \"the 27-year-old sustained the blow to his right foot in last month 's ` clasico ' win over real madrid .\"], 0.3394147717257183]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin ROUGE : [0.2388, 0.3023, 0.1724]\n",
      "New Candidate ROUGE : [0.5306, 0.5246, 0.5079]\n",
      "\n",
      "['ecb are to instigate a recruitment process involving head hunters sport recruitment international .', 'the main problem is that the job description has yet to be fixed .']\n",
      "[['ecb are to instigate a recruitment process involving head hunters sport recruitment international .', 'the main problem is that the job description has yet to be fixed .', 'the severe cuts that sky have been forced to make since agreeing their # 11m-a-match premier league deal is apparent even in the caribbean .', 'roy hodgson is launching roses 2015 , the annual clash between york and lancaster universities over 50 sports and 132 fixtures .'], 0.2803513638465095] \n",
      "\n",
      "['the ecb were expected to appoint a former england captain for the role .', 'the job description for the new cricket role has yet to be fixed .', 'sport recruitment international expected to suggest overseas candidates .']\n",
      "[[['alec stewart admitted he has had no contact with the ecb over the role of england cricket director', 'michael vaughan has been among the leading candidates to take up the newly-created role with england', 'roy hodgson is launching roses 2015 , the annual clash between york and lancaster universities'], 0.18513560414497496], [['ecb are to instigate a recruitment process involving head hunters sport recruitment international .', 'the main problem is that the job description has yet to be fixed .', 'the severe cuts that sky have been forced to make since agreeing their # 11m-a-match premier league deal is apparent even in the caribbean .', 'roy hodgson is launching roses 2015 , the annual clash between york and lancaster universities over 50 sports and 132 fixtures .'], 0.2803513638465095], [['the ecb are to spread the net far wider than expected in their search for the director of cricket to replace the axed paul downton .', 'it was widely believed that the new ecb regime led by chief executive tom harrison and chairman colin graves would waste little time in appointing from a short list of former england captains michael vaughan , andrew strauss and alec stewart .', 'roy hodgson is launching roses 2015 , the annual clash between york and lancaster universities over 50 sports and 132 fixtures .', \"nigel farage was spotted in the tory heartland that is the halford hewitt golf tournament played by public school old boys ' teams .\"], 0.18473731652975492]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop =0\n",
    "with open(new_data_path, 'w', encoding='utf-8') as f:\n",
    "    writer = jsonlines.Writer(f)\n",
    "    \n",
    "    for data in data_list:\n",
    "        candidates = data['candidates']\n",
    "        article = data['article']\n",
    "        abstract = data[\"abstract\"]\n",
    "\n",
    "\n",
    "        summaries = [cand[0] for cand in candidates]    \n",
    "        encoded_cand_set = [[bert_encode(s, 180) for s in cs] for cs in summaries]\n",
    "        threshold = min([get_rouge(abstract, cand[0]) for cand in candidates]) \n",
    "\n",
    "        sent_set = []\n",
    "\n",
    "\n",
    "        for i, encoded_cand in enumerate(encoded_cand_set):\n",
    "            for j, encoded_sent in enumerate(encoded_cand):\n",
    "        \n",
    "                sent_id = sum([len(prev) for prev in encoded_cand_set[:i]])+j\n",
    "                sent_set.append((sent_id, encoded_sent, candidates[i][0][j]))\n",
    "\n",
    "        reduced_cand_ids = get_candidate_set(sent_set)\n",
    "        reduced_cand_sents = [[sent_set[i][2] for i in ids] for ids in reduced_cand_ids]\n",
    "\n",
    "\n",
    "        # Drop candidate which has lower score than threshold\n",
    "        rouge_cands_set = []\n",
    "        for c in reduced_cand_sents:\n",
    "            score = get_rouge(abstract, c)\n",
    "            rouge_cands_set.append((score, c))\n",
    "\n",
    "        rouge_cands_set = sorted(rouge_cands_set, key=lambda x: x[0], reverse=True)\n",
    "        fined_cands_set = [sc for sc in rouge_cands_set if sc[0] >= threshold]\n",
    "\n",
    "        ## Redundancy score of Original Candidates\n",
    "        origin_redun = compute_txt_redundancy_score(summaries)\n",
    "        origin_scores = []\n",
    "        for re_sc, (ro_sc, sent) in zip(origin_redun, [(get_rouge(abstract, cs[0]), '\\n'.join(cs[0])) for cs in candidates]):\n",
    "            origin_scores.append((re_sc.item(), ro_sc, sent))\n",
    "\n",
    "        origin_scores = sorted(origin_scores, key=lambda x: -x[0]*0.1 +x[1], reverse=True)\n",
    "        \n",
    "        # Save Top-1 Score\n",
    "        origin_redun_scores.append(origin_scores[0][0])\n",
    "        origin_ref_rouges.append(origin_scores[0][1])\n",
    "        \n",
    "\n",
    "        ## Redundancy score of Reconstructed Summaries\n",
    "        refined_cands_set_ = [cs[1] for cs in fined_cands_set]\n",
    "        redun_score = compute_txt_redundancy_score(refined_cands_set_)\n",
    "\n",
    "        scores = []\n",
    "        for re_sc, (ro_sc, sent) in zip(redun_score, [(cs[0], '\\n'.join(cs[1])) for cs in fined_cands_set]):\n",
    "            scores.append((re_sc.item(), ro_sc, sent))\n",
    "\n",
    "        scores = sorted(scores, key=lambda x: -x[0]*0.1 + x[1], reverse=True)\n",
    "        \n",
    "        # Save Top-1 Score\n",
    "        refine_redun_scores.append(scores[0][0])\n",
    "        refine_ref_rouges.append(scores[0][1])\n",
    "                \n",
    "        ## Redundancy score of Reference Summary\n",
    "        abstract_scores = compute_txt_redundancy_score([abstract])\n",
    "        \n",
    "        reconstructed_candidates = [s[:][-1].split('\\n') for s in scores[:3]]\n",
    "        \n",
    "        origin_cand_rouge = [round(get_rouge(abstract, cand[0]),4) for cand in candidates]\n",
    "        new_cand_rouge = [round(get_rouge(abstract, cand),4) for cand in reconstructed_candidates]\n",
    "        \n",
    "        print(\"Origin ROUGE : {}\".format(origin_cand_rouge))\n",
    "        print(\"New Candidate ROUGE : {}\\n\".format(new_cand_rouge))\n",
    "                              \n",
    "        if max(new_cand_rouge) > max(origin_cand_rouge):\n",
    "            max_id = np.argmax(new_cand_rouge)\n",
    "            origin_max_id = np.argmax(origin_cand_rouge)\n",
    "            print(reconstructed_candidates[max_id])\n",
    "            print(candidates[origin_max_id],'\\n')\n",
    "            print(abstract)\n",
    "            \n",
    "            print(candidates,'\\n')\n",
    "            stop += 1\n",
    "        \n",
    "            if stop == 5:\n",
    "                break\n",
    "        \n",
    "        new_data = {'article':article, 'candidates':candidates, 'abstract':abstract, 'reconstructed_candidates': reconstructed_candidates}\n",
    "        writer.write(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the unusual format has been captured in a series of photographs by visual journalist anna erickson .',\n",
       "  \"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\",\n",
       "  'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'],\n",
       " [\"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\",\n",
       "  'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .',\n",
       "  'bud dodson , 57 , is a maintenance man who watches over the parking lot .'],\n",
       " ['the unusual format has been captured in a series of photographs by visual journalist anna erickson .',\n",
       "  'she came across them when she stopped to ask a seemingly homeless man for directions .',\n",
       "  'john worden , 52 , has been living in his $ 200 vehicle for years since his apartment burned down and he was left homeless .',\n",
       "  'bud dodson , 57 , watches over the parking lot in exchange for a semi-permanent spot .']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand = [[['the unusual format has been captured in a series of photographs by visual journalist anna erickson .', \"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\", 'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'], 0.32618005880037965], [[\"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\", 'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .', 'bud dodson , 57 , is a maintenance man who watches over the parking lot .'], 0.2774552491533624], [['the unusual format has been captured in a series of photographs by visual journalist anna erickson .', 'she came across them when she stopped to ask a seemingly homeless man for directions .', 'john worden , 52 , has been living in his $ 200 vehicle for years since his apartment burned down and he was left homeless .', 'bud dodson , 57 , watches over the parking lot in exchange for a semi-permanent spot .'], 0.2726937669376694]] \n",
    "\n",
    "cands = [c[0] for c in cand]\n",
    "cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.456521734215501\n",
      "0.41758241268445845\n"
     ]
    }
   ],
   "source": [
    "#gsum + refactor\n",
    "new = ['the unusual format has been captured in a series of photographs by visual journalist anna erickson.', # gsum or bart\n",
    "       \"around 30 drivers live in rvs in a parking lot in seattle's sodo area.\", # refactor\n",
    "       'she came across them when she stopped to ask a seemingly homeless man for directions.'] # gsum\n",
    "\n",
    "ri = ['the unusual format has been captured in a series of photographs by visual journalist anna erickson .',\n",
    "      \"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\",\n",
    "     'she came across them when she stopped to ask a seemingly homeless man for directions .']\n",
    "\n",
    "#bart\n",
    "origin = ['the unusual format has been captured in a series of photographs by visual journalist anna erickson .',\n",
    "          \"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\",\n",
    "          'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'] \n",
    "\n",
    "real = [\"around 30 people live a floating life in seattle 's sodo ( south of downtown ) area in their rvs .\",\n",
    "        'there is one parking lot in particular where the owner lets them act as watchmen in exchange for a spot to live .',\n",
    "        'visual journalist anna erickson , who photographed the community , said they are just grateful to have a home .']\n",
    "\n",
    "print(get_rouge(real, ri))\n",
    "print(get_rouge(real, new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for c in cands:\n",
    "    for s in c:\n",
    "        tmp.append((get_rouge(real, [s]), s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.37499999545,\n",
       "  \"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\"),\n",
       " (0.3692307660307693,\n",
       "  \"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\"),\n",
       " (0.26865671294274895,\n",
       "  'bud dodson , 57 , watches over the parking lot in exchange for a semi-permanent spot .'),\n",
       " (0.23529411404844294,\n",
       "  'the unusual format has been captured in a series of photographs by visual journalist anna erickson .'),\n",
       " (0.23529411404844294,\n",
       "  'the unusual format has been captured in a series of photographs by visual journalist anna erickson .'),\n",
       " (0.21212120877869609,\n",
       "  'bud dodson , 57 , is a maintenance man who watches over the parking lot .'),\n",
       " (0.12121211786960524,\n",
       "  'she came across them when she stopped to ask a seemingly homeless man for directions .'),\n",
       " (0.08219177672358811,\n",
       "  'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'),\n",
       " (0.08219177672358811,\n",
       "  'john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .'),\n",
       " (0.07999999574755579,\n",
       "  'john worden , 52 , has been living in his $ 200 vehicle for years since his apartment burned down and he was left homeless .')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sorted(tmp, key=lambda x : x[0], reverse=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4597701101334391"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_level_cand = [\"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\",\n",
    "                  \"around 30 drivers live in rvs in a parking lot in seattle 's sodo area .\",\n",
    "                  'bud dodson , 57 , watches over the parking lot in exchange for a semi-permanent spot .']\n",
    "\n",
    "get_rouge(real, sent_level_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23529411404844294\n",
      "0.37499999545\n",
      "0.08219177672358811\n"
     ]
    }
   ],
   "source": [
    "ext_1 = ['the unusual format has been captured in a series of photographs by visual journalist anna erickson .']\n",
    "ext_2 = [\"meet bud dodson , 57 , and welcome to his home : an rv in seattle 's sodo where he watches over the parking lot in exchange for a spot\"]\n",
    "ext_3 = ['john worden , 52 , has been living in his vehicle for years since his apartment burned down and he was left homeless .']\n",
    "\n",
    "print(get_rouge(real, ext_1))\n",
    "print(get_rouge(real, ext_2))\n",
    "print(get_rouge(real, ext_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23529411404844294\n",
      "0.3692307660307693\n",
      "0.12121211786960524\n",
      "0.456521734215501\n"
     ]
    }
   ],
   "source": [
    "for se in ri:\n",
    "    print(get_rouge(real, [se]))\n",
    "    \n",
    "\n",
    "print(get_rouge(real, ri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Origin Redundancy score : {}\".format(round(np.mean(origin_redun), 4)))\n",
    "print(\"Origin cosine similarity between document and summaries : {}\".format(round(np.mean(origin_doc_sims), 4)))\n",
    "print(\"Origin ROUGE score between reference and summaries : {}\".format(round(np.mean(origin_ref_rouges), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Origin Redundancy score : {}\".format(round(np.mean(refine_redun), 4)))\n",
    "print(\"Origin cosine similarity between document and summaries : {}\".format(round(np.mean(refine_doc_sims), 4)))\n",
    "print(\"Origin ROUGE score between reference and summaries : {}\".format(round(np.mean(refine_ref_rouges), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
