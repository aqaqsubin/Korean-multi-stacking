정보기술의 발전으로 일상 생활은 편리해 졌으며 다양한 정보기술 서비스를 통해 문화적 혜택을 누리고 있다.

그러나 장애인들은 정보기술의 접근성 한계로 인해 다양한 정보기술 서비스를 제공 받지 못하고 있다.

이에, 본 논문에서는 장애인에게 정보기술 서비스의 접근성을 높이기 위한 객체인식 및 음성 서비스 아키텍쳐를 제안하고자 한다.

특히 시각장애인이 사물(객체)의 인식 서비스와 음성 서비스를 제공받을 수 있도록 한다.

시각장애인은 모바일 디바이스를 이용하여 원하는 사물을 인식하고, 인식된 객체 정보는 음성으로 서비스하여 시각장애인이 어떤 사물인지를 인식할 수 있도록 한다.

모바일 환경에서 객체를 인식할 수 있도록 딥러닝 기반의 학습된 모델인 모바일넷 모델을 이용하여 객체를 인식할 수 있도록 한다.

객체인식 서비스는 인식된 객체에 대해 음성 서비스를 제공할 수 있도록 음성인식과 음성변환 서비스를 제공하는 아마존의 알렉사 서비스와 연동한다.

본 논문에서는 이러한 객체 인식과 음성 서비스를 기반으로 3가지 측면에서 서비스를 제공할 수 있는 기반 아키텍쳐를 제안한다.

첫째는 인식된 객체에 대한 음성 서비스이며, 둘째는 인식 객체에 대한 개인화 음성 서비스, 마지막으로 알렉사 서비스를 이용하여 인식 객체에 대한 지식 서비스를 제공한다.

@highlight

장애인들은 정보기술 접근성에 한계가 있으므로 장애인의 정보기술 서비스 접근성을 높이기 위한 객체인식 및 음성 서비스 아키텍쳐를 제안하고자 하였다.

@highlight

모바일 디바이스를 이용하여 원하는 사물을 인식하고 음성으로 서비스하여 시각장애인이 어떤 사물인지를 인식하도록 하고 객체 인식과 음성 서비스를 기반으로 서비스를 제공하는 기반 아키텍쳐를 제안한다.

