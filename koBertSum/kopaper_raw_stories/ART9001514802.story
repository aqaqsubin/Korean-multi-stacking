기존의 배경 생성방법은 주로 시간에 따른 context만을 이용해 복잡한 환경에서는 적용하기 힘들다.

이러한 단점을 해결하기 위해, 본 논문에서는 움직이는 물체를 포함하지 않는 배경 영상을 생성하기 위해 시간에 따른 context와 공간에 따른 context를 융합한 새로운 배경 생성 방법을 제안한다.

제안한 방법은 먼저 샘플링된 프레임 이미지를 m*n의 블록으로 나누고 각각의 블록을 고정 블록과 비고정 블록으로 나눈다.

비고정 블록에 대해서, 각 블록의 시간적 context와 공간적 context를 모델링하기 위해 MRF 프레임워크를 이용한다.

MRF 프레임워크는 영상 픽셀과 연관된 특징과 같은 context에 독립된 entity를 모델링하는데 많이 이용되는 방법으로 본 논문에서는 비고정 블록에 대한 시간적 context와 공간적 context를 모델링하기 위해 이용된다.

실험결과는 제안한 방법이 기존의 시간에 따른 context만을 이용했을 경우보다 더 효율적임을 보여준다.

@highlight

기존의 배경 생성방법은 주로 시간에 따른 context만을 이용해 복잡한 환경에서는 적용하기 힘들다.

