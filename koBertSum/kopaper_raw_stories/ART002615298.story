최근 인공지능 딥러닝 분야는 컴퓨팅 자원의 높은 연산량과 가격 문제로 인해 상용화에 어려움이 존재했다.

본 논문은 더블 프루닝 기법을 적용하여 심층 신경망 모델들과 다수의 데이터 셋에서의 성능을 평가하고자 한다.

더블 프루닝은 기본의 네트워크 간소화(Network-

Slimming)과 파라미터 프루닝(Parameter-

Pruning)을 결합한다.

이는 기존의 학습에 중요하지 않는 매개변수를 절감하여 학습 정확도를 저해하지 않고 속도를 향상시킬 수 있다는 장점이 있다.

다양한 데이터 셋 학습 이후에 프루닝 비율을 증가시켜, 모델의 사이즈를 감소시켰다.

NetScore 성능 분석 결과 MobileNet-

V3가 가장 성능이 높게 나타났다.

프루닝 이후의 성능은 Cifar 10 데이터 셋에서 깊이 우선 합성곱 신경망으로 구성된 MobileNet-

V3이 가장 성능이 높았고, 전통적인 합성곱 신경망으로 이루어진 VGGNet, ResNet 또한 높은 폭으로 성능이 증가함을 확인하였다.

@highlight

본고는 더블 프루닝 기법을 적용 심층 신경망 모델과 데이터 셋에서의 성능을 평가한다.

@highlight

NetScore 성능 분석 결과 MobileNet-

@highlight

V3가 가장 성능이 높았고 프루닝 이후 성능은 MobileNet-

@highlight

V3이 가장 성능이 높았고 VGGNet, ResNet 또한 증가했다.

