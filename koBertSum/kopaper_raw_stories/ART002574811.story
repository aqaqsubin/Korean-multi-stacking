인공지능 시스템의 신뢰도와 유용성을 높이기 위해 최근 연구에서는 설명가능 인공지능이라는 개념을 통해 시스템의 결과에 대한 설명 방법을 제안하고 있다.

그 중 하나는 반 사실적 설명을 사용하는 것이다.

그러나 기존 방법은 범주형 특성값을 사용해 반 사실적 설명을 생성할 수 없고 인간은 복잡한 입력 값의 조합과 의사 결정 경계의 근삿값을 모두 분석할 수 없다.

본 논문에서는 인간이 인과관계를 이해하는 과정을 반영한 반 사실적 설명 방법을 제안한다.

Intelligibility type explanation을 기반으로 한 why not, how to, what if를 사용해 세 가지 순차적 단계를 통해 설명 인터페이스를 사용자들에게 제공한다.

제안한 인터페이스의 유효성을 확인하기 대출 예측을 수행하는 인공지능 시스템을 사용해 시나리오 기반의 실험을 수행하였다.

그 결과 제안된 설명 인터페이스를 사용할 경우 기존 시스템에 비해 신뢰도, 유용성 및 만족도가 향상되었다.

이를 통해 기존 블랙박스로 여겨지던 인공 지능 시스템을 이해하는데 제안한 설명 인터페이스가 도움이 된다는 것을 확인할 수 있었다.

@highlight

인간이 인과관계를 이해하는 과정을 반영한 반 사실적 설명 방법을 제안하고 설명 인터페이스를 사용할 경우 기존 시스템에 비해 신뢰도, 유용성 및 만족도가 향상되었고 기존 블랙박스로 여겨지던 인공 지능 시스템을 이해하는데 제안한 설명 인터페이스가 도움됨을 증명했다.

