이 논문의 목적은 인공지능이 윤리적으로 행동하는 것이 가능한가를 고찰하는 것이다.

과학기술의 발전으로 윤리적 대상뿐만 아니라 윤리적 주체의 범위가 인공지능에까지 확대될 때 우리는 필연적으로 도덕적 인공행위자를 상정하게 된다.

그의 자발적 행위가 인간뿐만 아니라 세계에 영향을 미칠 때 우리는 인공행위자가 도덕적으로 행위하길 기대하기 때문이다.

그렇다면 도덕적 인공행위자가 가능하기 위해 우리는 어떻게 해야 할까?

그의 행동에 얼마만큼의 책임을 부여해야 할까?

이는 필연적으로 인간의 도덕적 추론에 대한 반성을 이끌게 된다.

인간의 도덕적 추론이 감정에 원천을 갖는다면 도덕적 인공행위자에게 감정능력을 갖게 하는 것이 필수적이다.

그러나 도덕적 인공행위자가 성공한다 할지라도 그에게 곧바로 도덕적, 법적 책임과 권리를 부여할 수 있을까?

우리가 책임져야 할 도덕적 행동이란 감성과 이성의 조화를 통한 자신의 행동을 이해하고, 자신의 행위를 최종적으로 합리적인 방식으로 선택할 수 있는 경우이다.

그러나 이를 위해 두 가지 전제조건이 만족되어야 한다.

책임은 사회적 관계에 의해 발생하는 것이며, 이는 의사소통의 가능성에 의존한다는 것이다.

책임개념은 사회적 인정에 의해 만들어진다.

따라서 도덕적 인공행위자가 자신의 행위에 대한 책임을 가지기 위해서는 인정투쟁이 필요하다.

책임의 귀속여부는 결국 이런 인정투쟁을 통해 형성된 사회적 산물이라 볼 수 있기 때문이다.

@highlight

이 논문의 목적은 인공지능이 윤리적으로 행동하는 것이 가능한가를 고찰하는 것이다.

@highlight

그렇다면 도덕적 인공행위자가 가능하기 위해 우리는 어떻게 해야 할까?

@highlight

그의 행동에 얼마만큼의 책임을 부여해야 할까?

@highlight

이는 필연적으로 인간의 도덕적 추론에 대해 반성을 이끌게 된다.

