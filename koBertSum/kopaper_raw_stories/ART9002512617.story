다양한 방식과 형태로 수집되는 개인의 헬스 데이터는 과학적 연구목적으로 이차 활용된다.

국내외개인정보보호 법률은 과학적 연구를 위한 데이터 처리의 법적 근거로 정보 주체의 동의를 얻는 것 이외에 데이터의 익명성을 요구한다.

공공이익과 관련된 연구라면 정보 주체의 동의가 면제될 수 있는데, 이러한 양립 가능성을 적용하기 위해서는 법 제도 이외의 측면도 고려해야 한다.

본 논문의 연구 질문은 인공지능을 학습시키는 데 데이터가 활용된다는 점에서 시작한다.

인공지능 알고리즘의 특성을 우선 살펴보고 이러한 기술에 활용되는 헬스 데이터의 사례와 제기되는 문제점을 고찰하였다.

인공지능기술 특성의 틀 안에 갇혀있는 문제는 윤리 논의의 주제가 될 수 있다.

법률을 통해 준비하고 해석하기어려운 문제점으로 사전동의와 책임, 데이터 익명성에 대한 신화, 위험점수와 알고리즘적 차별을 설명하였다.

그리고 문제해결을 위해 변화를 꾀한 국내외 법률의 데이터처리 원칙에 대한 입법 과정과 법률조항을 분석하여 해결을 위한 단서를 찾아보았다.

결론에서 ‘독(毒)’을 제거하는 데이터 처리, 사전적 절차로서의 법 제도와 조화, 사후적 판단을 위한 알고리즘의 투명한 설계를 제언하였다.

@highlight

국내·외 개인정보보호 법률은 과학적 연구를 위한 데이터 처리의 법적 근거로 정보 주체의 동의를 얻는 것 이외에 데이터의 익명성을 요구하고 있다.

@highlight

본 논문은 인공지능을 학습시키는 데 데이터가 활용된다는 점에서 시작하여 인공지능 알고리즘의 특성을 살펴보고 기술에 활용되는 헬스 데이터의 사례와 제기되는 문제점을 고찰했다.

